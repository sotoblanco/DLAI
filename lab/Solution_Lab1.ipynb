{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your first neural network in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re hire as a Junior Data Scientist to work on a subscription streaming service. It is your first day in the job, you are setting up your stuff at your new desk, and suddenly, you get an email from Andrew Ng the Data Science lead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/img_0136.png\" width=\"600\" height=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You got your first task and it is important for the future of the company, let's get into the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get and transform the data\n",
    "\n",
    "To begin, data preparation is crucial. In the real world, you'll typically retrieve data from a database. This often involves requesting permissions from DevOps teams and filing tickets with the data engineering team to obtain the necessary data. Once acquired, the data then needs to be preprocessed before it can be fed into your model.\n",
    "\n",
    "For now, let's skip the data engineering part and just use a small dataset of 10 customers and convert it into tensors to use in our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of average monthly data usage (in GB) for 10 customers\n",
    "avg_month_usage = [\n",
    "    5.2,  # Customer 1: Low usage, might churn\n",
    "    25.8, # Customer 2: High usage, likely to stay\n",
    "    1.5,  # Customer 3: Very low usage, high churn risk\n",
    "    18.7, # Customer 4: Moderate usage\n",
    "    10.1, # Customer 5: Low-ish usage\n",
    "    30.5, # Customer 6: Very high usage, loyal\n",
    "    7.3,  # Customer 7: Low usage\n",
    "    22.0, # Customer 8: Good usage\n",
    "    3.9,  # Customer 9: Low usage, potential churn\n",
    "    15.0  # Customer 10: Moderate usage\n",
    "]\n",
    "\n",
    "# List of churn status (0 = No Churn, 1 = Churn) for the same 10 customers\n",
    "churn = [\n",
    "    1,    # Customer 1: Churned\n",
    "    0,    # Customer 2: Did not churn\n",
    "    1,    # Customer 3: Churned\n",
    "    0,    # Customer 4: Did not churn\n",
    "    1,    # Customer 5: Churned\n",
    "    0,    # Customer 6: Did not churn\n",
    "    1,    # Customer 7: Churned\n",
    "    0,    # Customer 8: Did not churn\n",
    "    1,    # Customer 9: Churned\n",
    "    0     # Customer 10: Did not churn\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_month_usage_tensor:\n",
      "tensor([[ 5.2000],\n",
      "        [25.8000],\n",
      "        [ 1.5000],\n",
      "        [18.7000],\n",
      "        [10.1000],\n",
      "        [30.5000],\n",
      "        [ 7.3000],\n",
      "        [22.0000],\n",
      "        [ 3.9000],\n",
      "        [15.0000]])\n",
      "\n",
      "churn_tensor:\n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "avg_month_usage_tensor = torch.tensor(avg_month_usage).float().reshape(-1, 1)\n",
    "churn_tensor = torch.tensor(churn).float()\n",
    "\n",
    "print(f\"avg_month_usage_tensor:\\n{avg_month_usage_tensor}\\n\\nchurn_tensor:\\n{churn_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code to create a ``TensorDataset`` and ``DataLoader`` for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy DataLoader created with 10 samples.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4 # Adjusted batch size for smaller dataset\n",
    "num_samples = len(avg_month_usage_tensor)\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "customer_dataset = TensorDataset(avg_month_usage_tensor, churn_tensor)\n",
    "customer_dataloader = DataLoader(customer_dataset, batch_size=batch_size, shuffle=True)\n",
    "print(f\"Dummy DataLoader created with {len(customer_dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Intialize the model\n",
    "\n",
    "We will be working with a binary classification problem, for this we need:\n",
    "\n",
    "- Define the NN layer for output\n",
    "- Select the loss function\n",
    "- Set the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model defined: BinaryClassifier(\n",
      "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "Loss function defined: BCEWithLogitsLoss()\n",
      "Optimizer defined: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define the Model (Single Layer) ---\n",
    "# For a binary classification, the output layer typically has 1 neuron.\n",
    "# We'll use a simple linear layer.\n",
    "# The input_features should match the number of features in your dataset.\n",
    "input_features = 1 \n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple single-layer neural network for binary classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1) # Single linear layer for output\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor (logits).\n",
    "        \"\"\"\n",
    "        return self.linear(x)\n",
    "\n",
    "model = BinaryClassifier(input_features)\n",
    "print(\"Model defined:\", model)\n",
    "\n",
    "# --- 2. Define the Loss Function ---\n",
    "# BCEWithLogitsLoss combines a Sigmoid layer and the BCELoss in one single class.\n",
    "# This version is more numerically stable than using a plain Sigmoid followed by BCELoss.\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "print(\"Loss function defined:\", criterion)\n",
    "\n",
    "# --- 3. Define the Optimizer ---\n",
    "# Stochastic Gradient Descent (SGD)\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "print(\"Optimizer defined:\", optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop\n",
    "\n",
    "This is where you will get hands-on the model, you need to define everything learned to build the training loop:\n",
    "\n",
    "- Reset the gradients\n",
    "- Forward pass\n",
    "- Calculate loss\n",
    "- Backward pass and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_classifier(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Performs the training loop for a binary classification model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The PyTorch model to be trained.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader providing training data.\n",
    "        criterion (torch.nn.Module): The loss function (e.g., nn.BCEWithLogitsLoss).\n",
    "        optimizer (torch.optim.Optimizer): The optimizer (e.g., optim.SGD).\n",
    "        num_epochs (int): The number of epochs to train the model.\n",
    "    \"\"\"\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad() # omit\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            # Ensure labels are float and have the correct shape (e.g., [batch_size, 1])\n",
    "            loss = criterion(outputs, labels.float().unsqueeze(1)) # omit\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward() # omit\n",
    "            optimizer.step() # omit\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 0.7107\n",
      "Epoch 2/2, Loss: 0.7107\n",
      "❌ Function call test failed: step was not called.\n"
     ]
    }
   ],
   "source": [
    "from unittests import test_train_binary_classifier\n",
    "\n",
    "test_train_binary_classifier(train_binary_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Run the Training Loop ---\n",
    "print(\"\\nStarting training...\")\n",
    "train_binary_classifier(model, customer_dataloader, criterion, optimizer, num_epochs=10) # Increased epochs for small dataset\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "You've run your first model and now have some insights into how things work, including the key components you can't miss in a training pipeline using PyTorch. You're ready to get back to Andrew and ask for more challenges. Let's head on to the next lesson to see more about your upcoming task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
